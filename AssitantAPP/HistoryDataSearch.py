# -*- coding: utf-8 -*-
"""
HistoryDataSearch.py   æœ€å¾Œæ›´æ–°-> 2025-05-15
By Tseng-Tasi
------------------------------------------------------------
ğŸŒŸ åŠŸèƒ½ç¸½è¦½
------------------------------------------------------------
1. è®€å…¥ä¸‰ä»½ä¾†æº CSV
   â€¢ format_clean.csv           â†’ åˆæ³•ã€Œæ ¸åƒ¹é¡åˆ¥ã€æ¸…å–®
   â€¢ IndexSQL_find.csv          â†’ ç‰¹æä»£ç¢¼å‰äº”ç¢¼ â†” åŠŸèƒ½é¡åˆ¥ï¼ˆæ­¤ç‰ˆåƒ…ç”¨ä¾†å…ˆæ¥è³‡æ–™ï¼‰
   â€¢ åƒ¹é‡èª¿æŸ¥å“é …108-112.csv    â†’ æ­·å²åƒ¹é‡èª¿æŸ¥è³‡æ–™ï¼ˆæ¬²æ¨™è¨˜ä¹‹ä¸»é«”ï¼‰

2. å°ä¸‰å¼µè¡¨éœ€è¦æ¯”å°çš„æ¬„ä½åŸ·è¡Œã€Œå­—ä¸²æ¨™æº–åŒ–ã€ï¼š
   â€¢ å»å‰å¾Œç©ºç™½ã€åˆä½µå¤šé‡ç©ºç™½ã€å…¨å½¢â†’åŠå½¢ã€è½‰å°å¯«
   â€¢ ç”¢ç”Ÿ *_clean æ¬„ä½ï¼Œä¸ç ´å£åŸå§‹å…§å®¹

3. å…ˆä»¥ã€Œç‰¹æä»£ç¢¼å‰äº”ç¢¼ã€æŠŠ åƒ¹é‡èª¿æŸ¥è³‡æ–™ Ã— IndexSQL_find é€²è¡Œ inner merge

4. å†ä»¥ã€Œæ ¸åƒ¹é¡åˆ¥ã€(clean) èˆ‡ format_clean åš left mergeï¼Œé–‹å•Ÿ indicator
   -> è‡ªå‹•ç”¢ç”Ÿ _merge æ¬„ï¼Œå¯å¾—å€¼ {both, left_only}

5. é»æ•¸è®Šæ›´è¨˜éŒ„ = 1  â‡” _merge == 'both'

6. ç§»é™¤æš«ç”¨æ¬„ä½ã€é‡æ–°æ’æ¬„ä½é †åºã€è¼¸å‡º > HistoryData.csv
------------------------------------------------------------
âš ï¸ è®Šæ›´æé†’
------------------------------------------------------------
â— è‹¥ç¢ºå¯¦éœ€è¦ã€Œæ ¸åƒ¹é¡åˆ¥ä¹Ÿå¿…é ˆå­˜åœ¨æ–¼ IndexSQL_find['åç¨±']ã€ï¼Œ
  è«‹æŠŠ STEP-B-2 ä¸‹æ–¹çš„ `df_format_valid` æ”¹æˆé›™é‡äº¤é›†æ¢ä»¶ï¼Œ
  è¨»è§£ä¸­å·²ç¤ºç¯„æ›¿æ›æ–¹æ³•ã€‚

â— å¦‚éœ€ä¿ç•™å¤§å°å¯«æ•æ„Ÿï¼Œå¯æŠŠ clean_str() çš„ `.lower()` é‚£è¡Œè¨»è§£æ‰ã€‚
------------------------------------------------------------
"""
import os
import re
import unicodedata
from typing import Tuple, Optional

import pandas as pd


# ---------- å…±ç”¨ï¼šå­—ä¸²æ¨™æº–åŒ– ---------------------------------------
def clean_str(s: str) -> str:
    """
    å°‡å­—ä¸²è½‰æˆçµ±ä¸€æ¯”å°æ ¼å¼ï¼š
      1. NFKC æ­£è¦åŒ– â†’ å…¨å½¢â†’åŠå½¢ã€å…¼å®¹å­—å…ƒæ”¶æ–‚
      2. strip()      â†’ å»å‰å¾Œç©ºç™½
      3. \s+ â†’ ' '    â†’ å¤šé‡ç©ºç™½å£“æˆå–®ä¸€åŠå½¢ç©ºç™½
      4. lower()      â†’ çµ±ä¸€å°å¯«ï¼ˆè‹¥éœ€ä¿ç•™å¤§å°å¯«ï¼Œç§»é™¤æ­¤è¡Œï¼‰
    NaN â†’ '' ä»¥é¿å…å¾ŒçºŒ .lower() å‡ºéŒ¯
    """
    if pd.isna(s):
        return ""
    s = unicodedata.normalize("NFKC", str(s))
    s = s.strip()
    s = re.sub(r"\s+", " ", s)
    s = s.lower()
    return s
# ------------------------------------------------------------------


def HistoryDataSearch(
    base_dir: str = r"D:\CYCU\113_WebCrawler\CODE",
    data_dir: Optional[str] = None,
    format_file: Optional[str] = None,
    index_file: Optional[str] = None,
    price_file: Optional[str] = None,
    output_file: Optional[str] = None
) -> Tuple[Optional[pd.DataFrame], str]:
    """
    è™•ç†æ­·å²è³‡æ–™æœå°‹ï¼Œæ¯”å°æ ¸åƒ¹é¡åˆ¥å’ŒåŠŸèƒ½é¡åˆ¥ï¼Œç”¢ç”Ÿé»æ•¸è®Šæ›´è¨˜éŒ„ã€‚

    Args:
        base_dir (str): åŸºç¤ç›®éŒ„è·¯å¾‘ï¼Œé è¨­ç‚º D:\CYCU\113_WebCrawler\CODE
        data_dir (Optional[str]): è³‡æ–™ç›®éŒ„è·¯å¾‘ï¼Œé è¨­ç‚º base_dir/data
        format_file (Optional[str]): format_clean.csv çš„å®Œæ•´è·¯å¾‘
        index_file (Optional[str]): IndexSQL_find.csv çš„å®Œæ•´è·¯å¾‘
        price_file (Optional[str]): åƒ¹é‡èª¿æŸ¥å“é …108-112.csv çš„å®Œæ•´è·¯å¾‘
        output_file (Optional[str]): è¼¸å‡ºæª”æ¡ˆ HistoryData.csv çš„å®Œæ•´è·¯å¾‘
    -------        
    Returns:
        ä¾è¦å‰‡ç”¢ç”Ÿã€Œé»æ•¸è®Šæ›´è¨˜éŒ„ã€ä¸¦è¼¸å‡º HistoryData.csv
    -------
    (DataFrame | None, str)
        â€¢ è‹¥æˆåŠŸï¼šå›å‚³çµæœ DataFrame èˆ‡ç‹€æ…‹è¨Šæ¯
        â€¢ è‹¥å¤±æ•—ï¼šDataFrame ç‚º Noneï¼Œè¨Šæ¯èªªæ˜éŒ¯èª¤åŸå› 
    """
    # ---------- 1. æª”æ¡ˆè·¯å¾‘è¨­å®š -----------------------------------
    data_dir = data_dir or os.path.join(base_dir, "data")
    format_file = format_file or os.path.join(data_dir, "format_clean.csv")
    index_file  = index_file  or os.path.join(data_dir, "IndexSQL_find.csv")
    price_file  = price_file  or os.path.join(data_dir, "åƒ¹é‡èª¿æŸ¥å“é …108-112_FINAL.csv")
    output_file = output_file or os.path.join(data_dir, "HistoryData.csv")

    try:
        # ---------- 2. è®€æª” --------------------------------------
        df_format = pd.read_csv(format_file, encoding="utf-8")
        df_index  = pd.read_csv(index_file,  encoding="utf-8")
        df_price  = pd.read_csv(price_file,  encoding="utf-8")

        # ---------- 3. æ¬„ä½æª¢æŸ¥ ----------------------------------
        required_cols = {
            "df_format": ["æ ¸åƒ¹é¡åˆ¥"],
            "df_index":  ["åç¨±", "åŠŸèƒ½é¡åˆ¥(å‰5ç¢¼)"],
            "df_price":  ["ç‰¹æä»£ç¢¼å‰äº”ç¢¼", "æ ¸åƒ¹é¡åˆ¥åç¨±"]
        }
        for df_name, cols in required_cols.items():
            missing = [c for c in cols if c not in locals()[df_name].columns]
            if missing:
                raise ValueError(f"{df_name} ç¼ºå°‘æ¬„ä½: {missing}")

        # ---------- 4. å»ºç«‹ *_clean æ¬„ä½ -------------------------
        df_format["æ ¸åƒ¹é¡åˆ¥_clean"]     = df_format["æ ¸åƒ¹é¡åˆ¥"].apply(clean_str)
        df_index["åç¨±_clean"]          = df_index["åç¨±"].apply(clean_str)
        df_price["æ ¸åƒ¹é¡åˆ¥åç¨±_clean"] = df_price["æ ¸åƒ¹é¡åˆ¥åç¨±"].apply(clean_str)

        # ---------- 5. å…ˆä»¥ã€Œç‰¹æä»£ç¢¼å‰äº”ç¢¼ã€é—œè¯åƒ¹é‡èª¿æŸ¥ & IndexSQL_find
        result = pd.merge(
            df_price,
            df_index[["åŠŸèƒ½é¡åˆ¥(å‰5ç¢¼)", "åç¨±_clean"]],
            left_on="ç‰¹æä»£ç¢¼å‰äº”ç¢¼",
            right_on="åŠŸèƒ½é¡åˆ¥(å‰5ç¢¼)",
            how="inner"
        )

        # ---------- 6. åªå– format_clean ä¸­ã€ŒåŒæ™‚å­˜åœ¨æ–¼ IndexSQL_findã€çš„æ ¸åƒ¹é¡åˆ¥
        """
        valid_categories = (
            df_format.loc[
                df_format["æ ¸åƒ¹é¡åˆ¥_clean"].isin(df_index["åç¨±_clean"]),
                "æ ¸åƒ¹é¡åˆ¥_clean"
            ].drop_duplicates()
        )
        df_format_valid = pd.DataFrame({"æ ¸åƒ¹é¡åˆ¥_clean": valid_categories})
        #---------- å¦‚æœè¼¸å‡ºæ˜¯ 0 æˆ–åªæœ‰é›¶æ˜Ÿå¹¾å€‹ï¼Œå°±ç¢ºå®šæ˜¯ã€Œé›™é‡æ¢ä»¶ã€æŠŠè³‡æ–™å…¨æ¿¾æ‰ã€‚
        print("step-check | valid_categories =", len(valid_categories))
        print(valid_categories[:20])        # çœ‹çœ‹å‰ 20 å€‹é•·ç”šéº¼æ¨£
        """
        df_format_valid = df_format[['æ ¸åƒ¹é¡åˆ¥_clean']].drop_duplicates()

        # ---------- 7. å†ç”¨æ ¸åƒ¹é¡åˆ¥ (clean) åšæ¯”å°ï¼Œç”¢ç”Ÿ _merge
        result = result.merge(
            df_format_valid,
            left_on="æ ¸åƒ¹é¡åˆ¥åç¨±_clean",
            right_on="æ ¸åƒ¹é¡åˆ¥_clean",
            how="left",
            indicator=True
        )

        # ---------- 8. è¨­å®šé»æ•¸è®Šæ›´è¨˜éŒ„ -------------------------
        result["é»æ•¸è®Šæ›´è¨˜éŒ„"] = (result["_merge"] == "both").astype(int)

        # ---------- 9. æ•´ç†æ¬„ä½é †åº & ç§»é™¤æš«ç”¨æ¬„ ----------------
        drop_cols = ["åç¨±_clean", "æ ¸åƒ¹é¡åˆ¥_clean", "_merge"]
        result = result.drop(columns=[c for c in drop_cols if c in result.columns])

        output_columns = [
            "å¹´ä»½", "ç‰¹æä»£ç¢¼", "ç‰¹æä»£ç¢¼å‰äº”ç¢¼", "æ ¸åƒ¹é¡åˆ¥åç¨±",
            "ä¸­è‹±æ–‡å“å", "ç”¢å“å‹è™Ÿ/è¦æ ¼", "å–®ä½", "æ”¯ä»˜é»æ•¸",
            "ç”³è«‹è€…ç°¡ç¨±", "è¨±å¯è­‰å­—è™Ÿ", "ä¸­æ–‡å“å", "è‹±æ–‡å“å",
            "é»æ•¸è®Šæ›´è¨˜éŒ„"
        ]
        # å…è¨±æœ‰æ¬„ä½ç¼ºå¤±ï¼ˆä¾‹å¦‚å¹´ä»½ï¼‰ï¼Œåƒ…ä¿ç•™å­˜åœ¨çš„æ¬„
        result = result[[c for c in output_columns if c in result.columns]]

        # ---------- 10. è¼¸å‡º ------------------------------------
        result.to_csv(output_file, encoding="utf-8", index=False)
        msg = (
            f"è™•ç†å®Œæˆï¼Œå…± {len(result)} ç­†è³‡æ–™ï¼›"
            f"é»æ•¸è®Šæ›´è¨˜éŒ„=1ï¼š{result['é»æ•¸è®Šæ›´è¨˜éŒ„'].sum()} ç­†\n"
            f"å·²è¼¸å‡º â†’ {output_file}"
        )
        return result, msg

    except FileNotFoundError as e:
        return None, f"æª”æ¡ˆä¸å­˜åœ¨ï¼š{e}"
    except ValueError as e:
        return None, f"è³‡æ–™æ¬„ä½éŒ¯èª¤ï¼š{e}"
    except Exception as e:
        return None, f"æœªé æœŸéŒ¯èª¤ï¼š{e}"


if __name__ == "__main__":
    # é è¨­è·¯å¾‘ï¼ˆä¾éœ€è¦ä¿®æ”¹ï¼‰
    df_out, status = HistoryDataSearch()
    print(status)